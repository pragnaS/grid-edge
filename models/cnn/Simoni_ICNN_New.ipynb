{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, SGDRegressor, ElasticNet, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#import xgboost as xgb\n",
    "from pylab import *\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.constraints import non_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPMU(phase,dpmu_data,phase_letter,letter):\n",
    "    for (columnName, columnData) in phase.iteritems():\n",
    "        i=0\n",
    "        if 'Meter' in columnName:\n",
    "            split = columnName.split('Meter')\n",
    "            house_name = f'Meter{letter}_'+ split[1]\n",
    "            i+=1\n",
    "            dpmu_values = pd.Series(columnData.values).str.replace(\"i\", \"j\").apply(lambda x: abs(complex(x)))\n",
    "            dpmu_data[house_name] = dpmu_values\n",
    "        else:\n",
    "            split_column_names = columnName.split('_')\n",
    "            house_name = 'house'+str(split_column_names[phase_letter])\n",
    "            dpmu_values = pd.Series(columnData.values).str.replace(\"i\", \"j\").apply(lambda x: abs(complex(x)))\n",
    "            dpmu_data[house_name] = dpmu_values\n",
    "    return dpmu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Input(month,input_player_df):\n",
    "    directory = fr'C:\\Users\\simoni\\OneDrive\\Documents\\grid-edge\\data\\summer\\input_csv\\{month}'\n",
    "    #directory = os.getcwd()\n",
    "    #directory = directory.replace('models\\cnn', 'data\\summer\\input_csv')\n",
    "    #directory = directory + '\\\\' + month;\n",
    "    print(directory)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if str(filename).startswith('25.csv'):\n",
    "            continue\n",
    "        player = pd.read_csv(os.path.join(directory, filename))\n",
    "        #print(filename)\n",
    "        #print(player)\n",
    "        player['grid'] = player['grid'].str.replace(\"i\", \"j\").apply(lambda x: complex(x))\n",
    "        node_id = player['id'].loc[0]\n",
    "        column_name_p = 'p_'+str(node_id)\n",
    "        column_name_q = 'q_'+str(node_id)\n",
    "    #change .head() value to target dataframe row number\n",
    "        input_player_df[column_name_p] = player['grid'].apply(lambda x: x.real).head(44640)\n",
    "        input_player_df[column_name_q] = player['grid'].apply(lambda x: x.imag).head(44640)\n",
    "    return input_player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_phaseA_aug = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\aug\\\\multi_voltageA.csv')\n",
    "dpmu_phaseB_aug = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\aug\\\\multi_voltageB.csv')\n",
    "dpmu_phaseC_aug = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\aug\\\\multi_voltageC.csv')\n",
    "\n",
    "dpmu_phaseA_july = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\july\\\\multi_voltageA.csv')\n",
    "dpmu_phaseB_july = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\july\\\\multi_voltageB.csv')\n",
    "dpmu_phaseC_july = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\july\\\\multi_voltageC.csv')\n",
    "\n",
    "dpmu_phaseA_june = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\june\\\\multi_voltageA.csv')\n",
    "dpmu_phaseB_june = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\june\\\\multi_voltageB.csv')\n",
    "dpmu_phaseC_june = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\june\\\\multi_voltageC.csv')\n",
    "\n",
    "dpmu_phaseA_sept = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\sept\\\\multi_voltageA.csv')\n",
    "dpmu_phaseB_sept = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\sept\\\\multi_voltageB.csv')\n",
    "dpmu_phaseC_sept = pd.read_csv('..\\\\..\\\\data\\\\summer\\\\targets\\\\trimmed_targets\\\\sept\\\\multi_voltageC.csv')\n",
    "\n",
    "#dpmu_phaseA_aug = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\aug\\multi_voltageA.csv')\n",
    "#dpmu_phaseB_aug = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\aug\\multi_voltageB.csv')\n",
    "#dpmu_phaseC_aug = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\aug\\multi_voltageC.csv')\n",
    "\n",
    "#dpmu_phaseA_july = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\july\\multi_voltageA.csv')\n",
    "#dpmu_phaseB_july = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\july\\multi_voltageB.csv')\n",
    "#dpmu_phaseC_july = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\july\\multi_voltageC.csv')\n",
    "\n",
    "#dpmu_phaseA_june = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\june\\multi_voltageA.csv')\n",
    "#dpmu_phaseB_june = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\june\\multi_voltageB.csv')\n",
    "#dpmu_phaseC_june = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\june\\multi_voltageC.csv')\n",
    "\n",
    "#dpmu_phaseA_sept = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\sept\\multi_voltageA.csv')\n",
    "#dpmu_phaseB_sept = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\sept\\multi_voltageB.csv')\n",
    "#dpmu_phaseC_sept = pd.read_csv(r'C:\\Users\\aniss\\grid-edge\\data\\summer\\targets\\trimmed_targets\\sept\\multi_voltageC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_phaseA_aug = dpmu_phaseA_aug.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseB_aug = dpmu_phaseB_aug.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseC_aug = dpmu_phaseC_aug.drop(['Meter5', '# timestamp'], axis=1)\n",
    "\n",
    "dpmu_phaseA_july = dpmu_phaseA_july.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseB_july = dpmu_phaseB_july.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseC_july = dpmu_phaseC_july.drop(['Meter5', '# timestamp'], axis=1)\n",
    "\n",
    "dpmu_phaseA_june = dpmu_phaseA_june.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseB_june = dpmu_phaseB_june.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseC_june = dpmu_phaseC_june.drop(['Meter5', '# timestamp'], axis=1)\n",
    "\n",
    "dpmu_phaseA_sept = dpmu_phaseA_sept.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseB_sept = dpmu_phaseB_sept.drop(['Meter5', '# timestamp'], axis=1)\n",
    "dpmu_phaseC_sept = dpmu_phaseC_sept.drop(['Meter5', '# timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseA = 0\n",
    "phaseB = 1\n",
    "phaseC = 2\n",
    "A = \"A\"\n",
    "B = \"B\"\n",
    "C = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_data_aug = pd.DataFrame()\n",
    "dpmu_data_july = pd.DataFrame()\n",
    "dpmu_data_june = pd.DataFrame()\n",
    "dpmu_data_sept = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_data_aug = DPMU(dpmu_phaseA_aug,dpmu_data_aug,phaseA, A)\n",
    "dpmu_data_aug = DPMU(dpmu_phaseB_aug,dpmu_data_aug, phaseB, B)\n",
    "dpmu_data_aug = DPMU(dpmu_phaseC_aug,dpmu_data_aug, phaseC, C)\n",
    "\n",
    "dpmu_data_july = DPMU(dpmu_phaseA_aug,dpmu_data_july,phaseA, A)\n",
    "dpmu_data_july = DPMU(dpmu_phaseB_aug,dpmu_data_july, phaseB, B)\n",
    "dpmu_data_july = DPMU(dpmu_phaseC_aug,dpmu_data_july, phaseC, C)\n",
    "\n",
    "dpmu_data_june = DPMU(dpmu_phaseA_aug,dpmu_data_june,phaseA, A)\n",
    "dpmu_data_june = DPMU(dpmu_phaseB_aug,dpmu_data_june, phaseB, B)\n",
    "dpmu_data_june = DPMU(dpmu_phaseC_aug,dpmu_data_june, phaseC, C)\n",
    "\n",
    "dpmu_data_sept = DPMU(dpmu_phaseA_aug,dpmu_data_sept,phaseA, A)\n",
    "dpmu_data_sept = DPMU(dpmu_phaseB_aug,dpmu_data_sept, phaseB, B)\n",
    "dpmu_data_sept = DPMU(dpmu_phaseC_aug,dpmu_data_sept, phaseC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_data = pd.DataFrame()\n",
    "dpmu_data = pd.concat([dpmu_data_june, dpmu_data_july,dpmu_data_aug,dpmu_data_sept], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpmu_data_2 = dpmu_data[0:175680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = \"aug\"\n",
    "july = \"july\"\n",
    "june = \"june\"\n",
    "sept = \"sept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_player_df_aug = pd.DataFrame()\n",
    "input_player_df_july = pd.DataFrame()\n",
    "input_player_df_june = pd.DataFrame()\n",
    "input_player_df_sept = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simoni\\OneDrive\\Documents\\grid-edge\\data\\summer\\input_csv\\aug\n",
      "C:\\Users\\simoni\\OneDrive\\Documents\\grid-edge\\data\\summer\\input_csv\\july\n",
      "C:\\Users\\simoni\\OneDrive\\Documents\\grid-edge\\data\\summer\\input_csv\\june\n",
      "C:\\Users\\simoni\\OneDrive\\Documents\\grid-edge\\data\\summer\\input_csv\\sept\n"
     ]
    }
   ],
   "source": [
    "input_player_df_aug = Input(aug,input_player_df_aug)\n",
    "input_player_df_july = Input(july,input_player_df_july)\n",
    "input_player_df_june = Input(june,input_player_df_june)\n",
    "input_player_df_sept = Input(sept,input_player_df_sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_player_df = pd.DataFrame()\n",
    "input_player_df = pd.concat([input_player_df_june,input_player_df_july,input_player_df_aug,input_player_df_sept], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    x, y = input_player_df.copy().to_numpy(), dpmu_data_2.copy().to_numpy()\n",
    "    x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x, y, test_size=0.33, shuffle=False) \n",
    "    return x_train_split, x_test_split, y_train_split, y_test_split, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    main_input = Input(shape=n_inputs, name='main_input')\n",
    "    x = Dense(1440, input_dim=n_inputs, activation='relu')(main_input)\n",
    "    # supposed to be y = x*(weights) + main_input*(weights)+ b .. for each layer\n",
    "    # things to test \n",
    "    # - changing the dense layer output size\n",
    "    # - # of layers\n",
    "    # non_neg may not be necessary ..\n",
    "    x = Dense(720, input_dim=n_inputs, activation='relu', kernel_constraint=non_neg())(x)\n",
    "    d = Dense(720, input_dim=n_inputs, activation='relu')(main_input)\n",
    "    y = keras.layers.Add()([x, d])\n",
    "    \n",
    "    x = Dense(360, input_dim=n_inputs, activation='relu', kernel_constraint=non_neg())(y)\n",
    "    d = Dense(360, input_dim=n_inputs, activation='relu')(main_input)\n",
    "    y = keras.layers.Add()([x, d])\n",
    "    \n",
    "    x = Dense(180, input_dim=n_inputs, activation='relu', kernel_constraint=non_neg())(y)\n",
    "    d = Dense(180, input_dim=n_inputs, activation='relu')(main_input)\n",
    "    y = keras.layers.Add()([x, d])\n",
    "    \n",
    "    x = Dense(90, input_dim=n_inputs, activation='relu', kernel_constraint=non_neg())(y)\n",
    "    d = Dense(90, input_dim=n_inputs, activation='relu')(main_input)\n",
    "    y = keras.layers.Add()([x, d])\n",
    "    \n",
    "    # result gives you V-V0 for DPMU..... can we update y_test to reflect this...\n",
    "    main_output = Dense(n_outputs, activation='relu', name='main_output')(y)\n",
    "    model = Model(inputs=[main_input], outputs=[main_output])\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(x, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = x.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(x):\n",
    "        # prepare data\n",
    "        x_train, x_test = x[train_ix], x[test_ix]\n",
    "        y_train, y_test = y_new[train_ix], y_new[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(x_train, y_train, verbose=1, epochs=100)\n",
    "        # evaluate model on test set\n",
    "        #mse = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "        y_pred = model.predict(x_test)\n",
    "        names = y_test.columns\n",
    "        df_y_pred = pd.DataFrame(y_pred,columns = names)\n",
    "        scaling_all = pd.concat([y_test,df_y_pred], keys=['y_test','y_pred'])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(scaling_all)\n",
    "        scaledDF = pd.DataFrame(scaler.transform(scaling_all),columns = names)\n",
    "        \n",
    "        scaled_y_pred = scaledDF[:57975]\n",
    "        scaled_y_test = scaledDF[57975:]\n",
    "        \n",
    "        L2_ratios = []\n",
    "        for index, row in scaled_y_test.iterrows():\n",
    "            L2_ratios.append(LA.norm(row))\n",
    "        \n",
    "        #dividing all y_pred by the L2 ratios:\n",
    "        ratio_index = 0\n",
    "        scaled_ratio_y_pred = []\n",
    "        for index, row in scaled_y_pred.iterrows():\n",
    "            scaled_ratio_y_pred.append(row/L2_ratios[ratio_index])\n",
    "            ratio_index += 1\n",
    "        \n",
    "        # store result\n",
    "        print(mse)\n",
    "        results.append(mse)\n",
    "    return scaled_ratio_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model using repeated k-fold cross-validation\n",
    "def train_model(x_train_split, y_train_split):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = x_train_split.shape[1], y_train_split.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(x_train_split):\n",
    "        # prepare data\n",
    "        x_train, x_test = x[train_ix], x[test_ix]\n",
    "        y_train, y_test = y_new[train_ix], y_new[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(x_train, y_train, verbose=1, epochs=100)\n",
    "        return model\n",
    "\n",
    "def evaluation_model(model, x_test_split, y_test_split):\n",
    "    y_pred = model.predict(x_test_split)\n",
    "    names = y_test_split.columns\n",
    "    df_y_pred = pd.DataFrame(y_pred,columns = names)\n",
    "    scaling_all = pd.concat([y_test_split,df_y_pred], keys=['y_test','y_pred'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(scaling_all)\n",
    "    scaledDF = pd.DataFrame(scaler.transform(scaling_all),columns = names)\n",
    "\n",
    "    scaled_y_pred = scaledDF[:57975]\n",
    "    scaled_y_test = scaledDF[57975:]\n",
    "\n",
    "    L2_ratios = []\n",
    "    for index, row in scaled_y_test.iterrows():\n",
    "        L2_ratios.append(LA.norm(row))\n",
    "\n",
    "    #dividing all y_pred by the L2 ratios:\n",
    "    ratio_index = 0\n",
    "    scaled_ratio_y_pred = []\n",
    "    for index, row in scaled_y_pred.iterrows():\n",
    "        scaled_ratio_y_pred.append(row/L2_ratios[ratio_index])\n",
    "        ratio_index += 1\n",
    "\n",
    "    # store result\n",
    "    print(mse)\n",
    "    results.append(mse)\n",
    "    return scaled_ratio_y_pred, scaled_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3311/3311 [==============================] - 67s 20ms/step - loss: 1028636409856.0000 - mean_absolute_error: 23277.0703\n",
      "Epoch 2/100\n",
      "3311/3311 [==============================] - 67s 20ms/step - loss: 2949.0635 - mean_absolute_error: 6.5090\n",
      "Epoch 3/100\n",
      "3311/3311 [==============================] - 69s 21ms/step - loss: 383.1609 - mean_absolute_error: 6.0632\n",
      "Epoch 4/100\n",
      "3311/3311 [==============================] - 72s 22ms/step - loss: 157.9884 - mean_absolute_error: 6.0048 8 - ETA: 5s - loss: 158.940\n",
      "Epoch 5/100\n",
      "3311/3311 [==============================] - 70s 21ms/step - loss: 124.5144 - mean_absolute_error: 5.9962\n",
      "Epoch 6/100\n",
      "3311/3311 [==============================] - 72s 22ms/step - loss: 122.5665 - mean_absolute_error: 5.9951 1s - loss: 122.6757\n",
      "Epoch 7/100\n",
      "3311/3311 [==============================] - 92s 28ms/step - loss: 117.3226 - mean_absolute_error: 5.9939\n",
      "Epoch 8/100\n",
      "3311/3311 [==============================] - 101s 31ms/step - loss: 117.3227 - mean_absolute_error: 5.9939\n",
      "Epoch 9/100\n",
      "3311/3311 [==============================] - 112s 34ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 10/100\n",
      "3311/3311 [==============================] - 110s 33ms/step - loss: 117.3227 - mean_absolute_error: 5.99392s - loss: 117.2620 - ETA: 0s - loss: 117.2798 - mean_absolute_erro\n",
      "Epoch 11/100\n",
      "3311/3311 [==============================] - 109s 33ms/step - loss: 117.3227 - mean_absolute_error: 5.9939\n",
      "Epoch 12/100\n",
      "3311/3311 [==============================] - 109s 33ms/step - loss: 117.3227 - mean_absolute_error: 5.9939\n",
      "Epoch 13/100\n",
      "3311/3311 [==============================] - 110s 33ms/step - loss: 117.3227 - mean_absolute_error: 5.99393s - loss: 117.3267 - mean_absolu - ETA: 2s - \n",
      "Epoch 14/100\n",
      "3311/3311 [==============================] - 106s 32ms/step - loss: 117.3228 - mean_absolute_error: 5.99399s - loss: 117.3017 - mean_absolute_erro - - ETA: 4s - loss: 117.2579 -  - ETA: 3s - loss: 117.2409 - mean_absolute - ETA: 2s - loss: 11\n",
      "Epoch 15/100\n",
      "3311/3311 [==============================] - 112s 34ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 16/100\n",
      "3311/3311 [==============================] - 92s 28ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 17/100\n",
      "3311/3311 [==============================] - 121s 36ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 18/100\n",
      "3311/3311 [==============================] - 96s 29ms/step - loss: 117.3229 - mean_absolute_error: 5.9939\n",
      "Epoch 19/100\n",
      "3311/3311 [==============================] - 110s 33ms/step - loss: 117.3227 - mean_absolute_error: 5.99391s - loss: 117.3739 - mean_absol\n",
      "Epoch 20/100\n",
      "3311/3311 [==============================] - 110s 33ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 21/100\n",
      "3311/3311 [==============================] - 115s 35ms/step - loss: 117.3229 - mean_absolute_error: 5.9939\n",
      "Epoch 22/100\n",
      "3311/3311 [==============================] - 117s 35ms/step - loss: 117.3226 - mean_absolute_error: 5.9939\n",
      "Epoch 23/100\n",
      "3311/3311 [==============================] - 112s 34ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 24/100\n",
      "3311/3311 [==============================] - 109s 33ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 25/100\n",
      "3311/3311 [==============================] - 115s 35ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 26/100\n",
      "3311/3311 [==============================] - 109s 33ms/step - loss: 117.3226 - mean_absolute_error: 5.9939\n",
      "Epoch 27/100\n",
      "3311/3311 [==============================] - 114s 34ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 28/100\n",
      "3311/3311 [==============================] - 157s 48ms/step - loss: 117.3227 - mean_absolute_error: 5.99390s - loss: 117.3406 - mean_absolute_error: 5\n",
      "Epoch 29/100\n",
      "3311/3311 [==============================] - 129s 39ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 30/100\n",
      "3311/3311 [==============================] - 118s 36ms/step - loss: 117.3230 - mean_absolute_error: 5.9939\n",
      "Epoch 31/100\n",
      "3311/3311 [==============================] - 125s 38ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 32/100\n",
      "3311/3311 [==============================] - 116s 35ms/step - loss: 117.3228 - mean_absolute_error: 5.9939\n",
      "Epoch 33/100\n",
      "3311/3311 [==============================] - 82s 25ms/step - loss: 117.3229 - mean_absolute_error: 5.9939\n",
      "Epoch 34/100\n",
      "3311/3311 [==============================] - 84s 25ms/step - loss: 117.3227 - mean_absolute_error: 5.9939 6s - los\n",
      "Epoch 35/100\n",
      "3311/3311 [==============================] - 108s 33ms/step - loss: 117.3226 - mean_absolute_error: 5.9939\n",
      "Epoch 36/100\n",
      "3311/3311 [==============================] - 109s 33ms/step - loss: 117.3228 - mean_absolute_error: 5.99392s - loss: 117.3259 - mean_\n",
      "Epoch 37/100\n",
      "3311/3311 [==============================] - 121s 36ms/step - loss: 117.3229 - mean_absolute_error: 5.9939\n",
      "Epoch 38/100\n",
      "3311/3311 [==============================] - 121s 37ms/step - loss: 117.3228 - mean_absolute_error: 5.99393s\n",
      "Epoch 39/100\n",
      "3311/3311 [==============================] - 115s 35ms/step - loss: 117.3227 - mean_absolute_error: 5.9939\n",
      "Epoch 40/100\n",
      "3311/3311 [==============================] - 112s 34ms/step - loss: 117.3228 - mean_absolute_error: 5.99396s - loss: 117.4262 - mean_ - ETA: 1s - loss: 117.3484 - me\n",
      "Epoch 41/100\n",
      "3311/3311 [==============================] - 114s 34ms/step - loss: 117.3227 - mean_absolute_error: 5.9939\n",
      "Epoch 42/100\n",
      "1517/3311 [============>.................] - ETA: 1:02 - loss: 117.3860 - mean_absolute_error: 5.9978"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-00bbe3237137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_split_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mscaled_ratio_y_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_y_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_split_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# summarize performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-4ec2a40f3023>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(x_train_split, y_train_split)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \"\"\"\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x_train_split, x_test_split, y_train_split, y_test_split, x, y = get_dataset()\n",
    "y_train_split_new = np.diff(y_train_split)\n",
    "y_test_split_new = np.diff(y_test_split)\n",
    "y_new = np.diff(y)\n",
    "# evaluate model\n",
    "model_trained = train_model(x_train_split, y_train_split_new)\n",
    "scaled_ratio_y_pred, scaled_y_test = evaluation_model(model_trained, x_test_split, y_test_split_new)\n",
    "# summarize performance\n",
    "#print('MSE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "print('MSE: %.3f (%.3f)' % (scaled_y_test, scaled_ratio_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
